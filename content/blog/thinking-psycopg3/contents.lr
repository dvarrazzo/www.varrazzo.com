title: Thinking psycopg3
---
pub_date: 2020-02-15
---
author: Daniele Varrazzo
---
tags:

psycopg
software
design
---
body:

I have been psycopg2_ maintainer since 2010; before that, `git says`__ that my
first contribution was in 2005. At that time, psycopg (one) was the tool to
use, and psycopg2 was an interesting experiment.

.. _psycopg2: https://www.psycopg.org/
.. __: https://github.com/psycopg/psycopg2/commit/4805a935690b1d618247267318a0ef7aa06c2378

In many years of using psycopg2 daily and reading about the expectations,
frustrations, surprises experienced by its users, I have been making my mind
about a better system, and if I had to release a version incompatible with the
past, those are some of the things I would change.


Adaptation system
=================

psycopg2 composes the queries (binding the arguments to the placeholders in
the SQL string) on the client, and sends to the server the complete query with
its values. It does it right, so it doesn't result in SQL injection
vulnerabilities, however the correct way of doing it should be to send the
query and its parameters separately (i.e. using the |PQexecParams|_ libpq
function rather than |PQexec|_).

On the pro side, separating the statements is a huge help for the query parser
and saves memory at parsing time. However the behaviour of the library would
change slightly:

- |PQexecParams| supports only one command at time: it would be no more
  possible to send several queries separated by semicolon in a single
  ``execute()``.

- psycopg2 helps solving some types ambiguities by attaching casts to the
  types represented as strings (e.g. the date 1/1/2020 is currently merged to
  the query as ``'2010-01-01'::date``). Using |PQexecParams| the trick
  wouldn't be available anymore (although the type can be specified otherwise
  in the query).

- Custom-defined adapters should be rewritten.

.. |PQexec| replace:: ``PQexec``
.. _PQexec: https://www.postgresql.org/docs/current/libpq-exec.html#LIBPQ-PQEXEC
.. |PQexecParams| replace:: ``PQexecParams``
.. _PQexecParams: https://www.postgresql.org/docs/current/libpq-exec.html#LIBPQ-PQEXECPARAMS

The main difference between the old adaptation protocol (called |ISQLQuote|_)
and the new one (which doesn't have a name yet, and probably should be
``ISQL``) is the use of the quotes, whereby the string ``O'Connor`` is passed
to the query as ``'O''Connor'``. In ``ISQL`` the string wouldn't undergo the
same transformation to add and escape quotes, and other types would be just
converted into strings in the PostgreSQL syntax, but wouldn't need to be
wrapped in quotes to create a SQL literal. Using ``ISQL`` as the fundamental
adaptation steps there would be some interesting improvements:

- adapting composite types and arrays would be a much straightforward matter,
- it opens the door to the use of `prepared statements`__, but especially
- the ``COPY FROM`` operation could take an iterable object yielding Python
  types instead of a file-like object to read; similarly ``COPY TO`` could
  return an iterable object yielding Python types.

.. __: https://www.postgresql.org/docs/current/libpq-exec.html#LIBPQ-PQPREPARE

I mean: this would be great! |COPY|_ is by far the most efficient way to
insert data into the database: using it via psycopg2 requires exposing the
data via a `file-like object`__, which not only is a weird interface, but it
requires people to roll their own adaptation format. Looking forward for:

.. code:: python

    curs.copy("COPY song (artist, title) FROM STDIN", [
        ("Sinead O'Connor", "Nothing Compares 2 U"),
        ('REM', "Losing my Religion"),
    ])

.. |ISQLQuote| replace:: ``ISQLQuote``
.. _ISQLQuote: https://www.psycopg.org/docs/extensions.html#psycopg2.extensions.ISQLQuote
.. |COPY| replace:: ``COPY``
.. _COPY: https://www.postgresql.org/docs/current/sql-copy.html
.. __: https://www.psycopg.org/docs/usage.html#using-copy-to-and-copy-from


Context managers and transactions
=================================

psycopg2 follows a de-facto standard (which was `widely discussed`__ but never
landed in the DBAPI specs), whereby connections manage a transaction when used
as context manager, by committing/rolling back on ``__exit__``. So the way to
use it would be:

.. code:: python

    conn = connect(DSN)
    try:
        # these are two separate transactions
        with conn:
            do_something(conn)
        with conn:
            do_something_else(conn)

.. __: https://mail.python.org/pipermail/db-sig/2012-November/thread.html

This is very useful, but it is a surprising behaviour: developers usually
expect an object implementing ``close()`` to be closed on context exit (as
files, and even cursors do). It also get in the way of managing different life
cycles on the connection, for instance if there is a pool a connection is
taken from:

.. code:: python

    with pool.getconn() as conn:
        with conn.cursor() as curs:
            do_someting(curs)

it is expected (and `vocally requested`__) that the connection is returned to the
pool at the end of the block.

.. __: https://github.com/psycopg/psycopg2/pull/17

Talking about transactions, PostgreSQL support for ``SAVEPOINT`` makes
possible to implement nested transactions (already implemented on top of
psycopg2 e.g. `by Django`__ and `in a stand-alone module`__).

.. __: https://docs.djangoproject.com/en/3.0/topics/db/transactions/#django.db.transaction.atomic
.. __: https://github.com/asqui/psycopg-nestedtransactions

Maybe it would be useful to add an explicit method to start an atomic block
(either a transaction or a savepoint, according to the current connection
state):

.. code:: python

    with connect(DSN) as conn:
        with conn.transaction():
            do_something()
            with conn.transaction():
                do_something_nested()

        with conn.transaction() as tx:
            do_something_else()
            # we were just testing and we don't really want to do this
            tx.rollback()

    # and here the connection is closed


Optional C module
=================

psycopg2 is a C extension module wrapping the libpq_, the PostgreSQL client
library. As such, in order to build, it requires a C compiler, Python, and
libpq development packages. It is a relatively low bar, but it can be a pain
nonetheless for several beginner users.

We tried to avoid the problem shipping a `wheel package`_, but the experience
has been `far from being a success`__,  marred by issues such as the possible
incompatibility between the libcrypto used by Python and by the libpq, the
lack of support for musl libc/Alpine Linux, broken assumptions (like `glibc
breaking backwards compatibility`__)... There's too magic in that.

.. _wheel package: https://pythonwheels.com/
.. __: https://github.com/psycopg/psycopg2/issues?utf8=%E2%9C%93&q=+label%3Awheel
.. __: https://github.com/pypa/manylinux/issues/305

.. _libpq: https://www.postgresql.org/docs/current/libpq.html

Mostly in order to support PyPy, during the years a few "python-only"
implementations have been developed: first a `ctypes implementation`__, to
which I contributed but which hasn't been maintained at the same feature level
of the C psycopg2. It was further forked into a `cffi implementation`__, whose
release numbers don't follow the original ones, which is mighty confusing.

.. __: https://github.com/mvantellingen/psycopg2-ctypes
.. __: https://github.com/chtd/psycopg2cffi

What I think is that psycopg3 should follow an approach similar to PyYAML
(I've seen it doing, I have to check how...), which tries to compile an
optimized version of the library and falls back to a Python implementation if
it fails.

psycopg3 would try to use the C module in preference of the Python module, but
if someone wanted to enforce the use of one specific implementation, an
environment variable could be used for the task, such as
``PSYCOPG3_IMPL={C|PYTHON}``, in the presence of which importing the module
would fail in case the requested implementation is not available.


Other improvements
==================

I've noted some of the ideas to implement in `a trello board`__ and in `an
issues milestone`__. Some of them weren't actually incompatible and ended up
implemented in psycopg2; some will have to wait.

.. __: https://trello.com/b/6tF2oHJ0/psycopg3
.. __: https://github.com/psycopg/psycopg2/milestone/4

A lot can be done if there is will:

- an async interface based on asyncio_ (as aiopg_ offers)
- async COPY methods (see `issue #428`_)
- better support for SQL_ASCII databases (which unlike their name are actually
  unencoded 8 bits, see `issue #519`_)
- `preparing cursors`_
- reorganising the extensions_ and extras_ module, which contain an
  heterogeneous assortment of objects, functions, constants...

.. _asyncio: https://docs.python.org/3.8/library/asyncio.html
.. _aiopg: https://github.com/aio-libs/aiopg
.. _issue #428: https://github.com/psycopg/psycopg2/issues/428
.. _issue #519: https://github.com/psycopg/psycopg2/issues/519
.. _preparing cursors: https://gist.github.com/dvarrazzo/3797445
.. _extensions: https://www.psycopg.org/docs/extensions.html
.. _extras: https://www.psycopg.org/docs/extras.html

I would be interested in starting the development of this project, and would
love to hear what areas should be the focus: I would like some discussion to
happen on the `Mailing List`_, so please subscribe_ and participate!

And if psycopg2 has been useful so far for you and your business and would
love to see a psycopg3 even more performing and easier to use, please consider
`sponsoring the development`__, thank you! ðŸ’“

.. _mailing list: https://www.postgresql.org/list/psycopg/
.. _subscribe: https://lists.postgresql.org/
.. __: https://github.com/sponsors/dvarrazzo/

---
image: /img/software/londiste.jpg
---
_discoverable: yes
